{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 172960.99it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 92090.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['HFH_001.hdr', 'HFH_002.hdr', 'HFH_003.hdr', 'HFH_004.hdr', 'HFH_005.hdr', 'HFH_006.hdr', 'HFH_007.hdr', 'HFH_008.hdr', 'HFH_009.hdr', 'HFH_010.hdr', 'HFH_011.hdr', 'HFH_012.hdr', 'HFH_013.hdr', 'HFH_014.hdr', 'HFH_015.hdr', 'HFH_016.hdr', 'HFH_017.hdr', 'HFH_018.hdr', 'HFH_019.hdr', 'HFH_020.hdr']\n",
      "5\n",
      "['HFH_021.hdr', 'HFH_022.hdr', 'HFH_023.hdr', 'HFH_024.hdr', 'HFH_025.hdr']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nibabel\n",
    "import os\n",
    "\n",
    "RAW_TRAIN_DATA_DIR = os.path.join(os.curdir, \"dataset\", \"raw\", \"Train\")\n",
    "RAW_TRAIN_LABEL_DIR = os.path.join(os.curdir, \"dataset\", \"raw\", \"Train\", \"Labels\")\n",
    "\n",
    "TRAIN_DATASET_DIR = os.path.join(os.curdir, \"dataset\", \"train\")\n",
    "VALIDATION_DATASET_DIR = os.path.join(os.curdir, \"dataset\", \"validation\")\n",
    "\n",
    "\n",
    "def get_splited_dataset_filenames(raw_train_dir, train_ratio):\n",
    "    train_names = [name for name in sorted(os.listdir(raw_train_dir))]\n",
    "    boundary = int(len(train_names) * train_ratio)\n",
    "    train_filenames = []\n",
    "    for filename in tqdm(train_names[:boundary]):\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        if \"hdr\" in ext:\n",
    "            train_filenames.append(filename)\n",
    "    val_filenames = []\n",
    "    for filename in tqdm(train_names[boundary:]):\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        if \"hdr\" in ext:\n",
    "            val_filenames.append(filename)\n",
    "    return train_filenames, val_filenames\n",
    "\n",
    "\n",
    "train_paths, val_paths = get_splited_dataset_filenames(RAW_TRAIN_DATA_DIR, 0.8)\n",
    "print(len(train_paths))\n",
    "print(train_paths)\n",
    "print(len(val_paths))\n",
    "print(val_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 351247.13it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 25/25 [00:06<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def init_trainset(filenames, raw_dataset_dir, raw_label_dir, train_data_dir):\n",
    "    for filename in tqdm(sorted(filenames)):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if \"hdr\" in ext:\n",
    "            label_image = nibabel.load(os.path.join(raw_label_dir, name + \"_Hipp_Labels\" + ext)).get_fdata()\n",
    "            label_image = label_image.squeeze()\n",
    "            indices = []\n",
    "            for index in range(label_image.shape[1]):\n",
    "                sliced_label_image = label_image[:, index, ...]\n",
    "                sliced_label_image = sliced_label_image.astype(np.int32)\n",
    "                pil_label_image = Image.fromarray(sliced_label_image).resize(\n",
    "                    (256, 256), Image.Resampling.NEAREST\n",
    "                )\n",
    "                scaled_label_image = np.array(pil_label_image)\n",
    "                if (scaled_label_image != 0).any():\n",
    "                    indices.append(index)\n",
    "                    dense_label_image = np.zeros((256, 256, 3))\n",
    "                    dense_label_image[scaled_label_image == 0, 0] = 1\n",
    "                    dense_label_image[scaled_label_image == 1, 1] = 1\n",
    "                    dense_label_image[scaled_label_image == 2, 2] = 1\n",
    "                    new_names = name.split(\"_\")[:2]\n",
    "                    new_filename = f\"{new_names[0]}_{new_names[1]}_{index:>03d}.npy\"\n",
    "                    new_path = os.path.join(train_data_dir, \"label\", new_filename)\n",
    "                    with open(new_path, \"wb\") as f:\n",
    "                        np.save(f, dense_label_image)\n",
    "\n",
    "            data_image = nibabel.load(\n",
    "                os.path.join(raw_dataset_dir, filename)\n",
    "            ).get_fdata()\n",
    "            data_image = data_image.squeeze()\n",
    "            for index in indices:\n",
    "                sliced_data_image = data_image[:, index, ...]\n",
    "                sliced_data_image = sliced_data_image.astype(np.int32)\n",
    "                pil_data_image = Image.fromarray(sliced_data_image).resize(\n",
    "                    (256, 256), Image.Resampling.NEAREST\n",
    "                )\n",
    "                scaled_data_image = np.array(pil_data_image)\n",
    "                str_index = str(index)\n",
    "                new_filename = f\"{name}_{index:>03d}.npy\"\n",
    "                new_path = os.path.join(train_data_dir, \"data\", new_filename)\n",
    "                with open(new_path, \"wb\") as f:\n",
    "                    np.save(f, scaled_data_image)\n",
    "\n",
    "all_filenames = get_splited_dataset_filenames(RAW_TRAIN_DATA_DIR, 1.0)[0]\n",
    "init_trainset(\n",
    "    all_filenames,\n",
    "    RAW_TRAIN_DATA_DIR,\n",
    "    RAW_TRAIN_LABEL_DIR,\n",
    "    TRAIN_DATASET_DIR,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:33<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "def init_validationset(filenames, raw_dataset_dir, raw_label_dir, validation_data_dir):\n",
    "    for filename in tqdm(sorted(filenames)):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if \"hdr\" in ext:\n",
    "            image = nibabel.load(os.path.join(raw_dataset_dir, filename)).get_fdata()\n",
    "            image = image.squeeze()\n",
    "\n",
    "            label_image = nibabel.load(\n",
    "                os.path.join(raw_label_dir, name + \"_Hipp_Labels\" + ext)\n",
    "            ).get_fdata()\n",
    "            label_image = label_image.squeeze()\n",
    "\n",
    "            for index in range(image.shape[1]):\n",
    "                sliced_image = image[:, index, ...]\n",
    "                sliced_image = sliced_image.astype(np.int32)\n",
    "                pil_image = Image.fromarray(sliced_image).resize(\n",
    "                    (256, 256), Image.Resampling.NEAREST\n",
    "                )\n",
    "                scaled_image = np.array(pil_image)\n",
    "                str_index = str(index)\n",
    "                new_filename = f\"{name}_{index:>03d}.npy\"\n",
    "                new_path = os.path.join(validation_data_dir, \"data\", new_filename)\n",
    "                with open(new_path, \"wb\") as f:\n",
    "                    np.save(f, scaled_image)\n",
    "\n",
    "                sliced_label_image = label_image[:, index, ...]\n",
    "                sliced_label_image = sliced_label_image.astype(np.int32)\n",
    "                pil_label_image = Image.fromarray(sliced_label_image).resize(\n",
    "                    (256, 256), Image.Resampling.NEAREST\n",
    "                )\n",
    "                scaled_label_image = np.array(pil_label_image)\n",
    "                dense_label_image = np.zeros((256, 256, 3))\n",
    "                dense_label_image[scaled_label_image == 0, 0] = 1\n",
    "                dense_label_image[scaled_label_image == 1, 1] = 1\n",
    "                dense_label_image[scaled_label_image == 2, 2] = 1\n",
    "                new_names = name.split(\"_\")[:2]\n",
    "                new_filename = f\"{new_names[0]}_{new_names[1]}_{index:>03d}.npy\"\n",
    "                new_path = os.path.join(validation_data_dir, \"label\", new_filename)\n",
    "                with open(new_path, \"wb\") as f:\n",
    "                    np.save(f, dense_label_image)\n",
    "\n",
    "\n",
    "init_validationset(\n",
    "    all_filenames, RAW_TRAIN_DATA_DIR, RAW_TRAIN_LABEL_DIR, VALIDATION_DATASET_DIR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 251758.94it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "RAW_TEST_DATA_DIR = os.path.join(os.curdir, \"dataset\", \"raw\", \"Test\")\n",
    "TEST_DATA_DIR = os.path.join(os.curdir, \"dataset\", \"test\")\n",
    "\n",
    "\n",
    "def init_testset(filenames, raw_dataset_dir, test_data_dir):\n",
    "    for filename in tqdm(sorted(filenames)):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if \"hdr\" in ext:\n",
    "            image = nibabel.load(os.path.join(raw_dataset_dir, filename)).get_fdata()\n",
    "            image = image.squeeze()\n",
    "\n",
    "            for index in range(image.shape[1]):\n",
    "                sliced_image = image[:, index, ...]\n",
    "                sliced_image = sliced_image.astype(np.int32)\n",
    "                pil_image = Image.fromarray(sliced_image).resize(\n",
    "                    (256, 256), Image.Resampling.NEAREST\n",
    "                )\n",
    "                scaled_image = np.array(pil_image)\n",
    "                new_filename = f\"{name}_{index:>03d}.npy\"\n",
    "                new_path = os.path.join(test_data_dir, new_filename)\n",
    "                with open(new_path, \"wb\") as f:\n",
    "                    np.save(f, scaled_image)\n",
    "\n",
    "\n",
    "test_filenames, _ = get_splited_dataset_filenames(RAW_TEST_DATA_DIR, 1)\n",
    "\n",
    "init_testset(test_filenames, RAW_TEST_DATA_DIR, TEST_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('keras')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1adc45b2727d29ffe2ebdf1744bac2997f1014da1e47286e1a4198fcda79fd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
