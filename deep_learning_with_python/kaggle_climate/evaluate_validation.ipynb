{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:01:50.619533: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 20:01:50.770334: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-17 20:01:51.442802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-17 20:01:51.442892: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-17 20:01:51.442900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/BASEL',\n",
       " './model/BUDAPEST',\n",
       " './model/DE',\n",
       " './model/DRESDEN',\n",
       " './model/DUSSELDORF',\n",
       " './model/HEATHROW',\n",
       " './model/KASSEL',\n",
       " './model/LJUBLJANA',\n",
       " './model/MAASTRICHT',\n",
       " './model/MALMO',\n",
       " './model/MONTELIMAR',\n",
       " './model/MUENCHEN',\n",
       " './model/OSLO',\n",
       " './model/PERPIGNAN',\n",
       " './model/ROMA',\n",
       " './model/SONNBLICK',\n",
       " './model/STOCKHOLM',\n",
       " './model/TOURS']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model_dirs = [\n",
    "    os.path.join(os.curdir, \"model\", name)\n",
    "    for name in sorted(os.listdir(os.path.join(os.curdir, \"model\")))\n",
    "]\n",
    "model_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:01:52.311608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.319693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.320183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.320668: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 20:01:52.329351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.329847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.330417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.912409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.913142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.913157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-11-17 20:01:52.913641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:01:52.913692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21757 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BUDAPEST_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 6, 8)]            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 6, 16)             1600      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,729\n",
      "Trainable params: 3,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = [tf.keras.models.load_model(model_dir) for model_dir in model_dirs]\n",
    "models[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_DIR = os.path.join(os.curdir, \"dataset\", \"sorted\")\n",
    "csv_filenames = sorted(os.listdir(CSV_DIR))\n",
    "csv_dataset = [\n",
    "    pd.read_csv(os.path.join(CSV_DIR, filename)) for filename in csv_filenames\n",
    "]\n",
    "print(len(csv_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>, <BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>, <BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>)\n",
      "tf.Tensor(\n",
      "[[ 1.11010855  1.34424888  1.34682202 -1.20851298 -0.38199123 -1.07646018\n",
      "  -1.09549112 -0.80998751 -1.33429094]\n",
      " [ 1.11010855  1.15869866  1.7487146  -1.15505695 -0.43793346 -1.07646018\n",
      "  -1.00108475 -0.64465741 -1.23109558]\n",
      " [-0.17993809  0.602048    1.69847803 -0.8877768  -0.43793346 -0.22197883\n",
      "  -1.18989749 -1.03543765 -1.23109558]\n",
      " [ 0.680093    0.41649778  1.04540259 -0.74879112  0.2147259   0.51703206\n",
      "  -0.96062487 -0.97531762 -0.92150951]\n",
      " [-0.17993809  1.43702399  0.8444563  -0.87708559 -0.30740159 -0.22197883\n",
      "  -0.67740576 -0.47932731 -0.79538185]\n",
      " [-1.03996918  0.97314844  0.81933801 -0.82362956 -0.43793346  0.23990298\n",
      "  -0.920165   -0.76489749 -0.99030641]], shape=(6, 9), dtype=float64)\n",
      "tf.Tensor([4.7], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_END_INDEX = 2922\n",
    "VALIDATION_END_INDEX = 3288\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    dataset: pd.DataFrame,\n",
    "    sequence_length,\n",
    "    batch_size,\n",
    "    train_end_index,\n",
    "    validation_end_index,\n",
    "):\n",
    "    data = dataset\n",
    "    for col in dataset.columns:\n",
    "        if \"temp_mean\" in col:\n",
    "            target = pd.DataFrame(dataset[col])\n",
    "            data = data.drop(columns=[\"DATE\"])\n",
    "            break\n",
    "    scaled_data = (data - data.mean(axis=0)) / data.std(axis=0)\n",
    "    train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=0,\n",
    "        end_index=train_end_index,\n",
    "    )\n",
    "    validation_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=train_end_index,\n",
    "        end_index=validation_end_index,\n",
    "    )\n",
    "    test_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=validation_end_index,\n",
    "    )\n",
    "    return (train_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "\n",
    "sequence_length = 6\n",
    "\n",
    "batch_dataset = [\n",
    "    get_dataset(csv_data, sequence_length, 32, TRAIN_END_INDEX, VALIDATION_END_INDEX)\n",
    "    for csv_data in csv_dataset\n",
    "]\n",
    "\n",
    "print(len(batch_dataset))\n",
    "print(batch_dataset[1])\n",
    "for data, label in batch_dataset[0][0]:\n",
    "    print(data[0])\n",
    "    print(label[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:03:22.173606: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 8ms/step - loss: 3.1302 - MAE: 1.4125\n",
      "12/12 [==============================] - 1s 8ms/step - loss: 3.4316 - MAE: 1.4174\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 3.0423 - MAE: 1.3951\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 4.6628 - MAE: 1.6595\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 2.7651 - MAE: 1.3485\n",
      "12/12 [==============================] - 1s 18ms/step - loss: 2.3369 - MAE: 1.2041\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 3.0638 - MAE: 1.3915\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 4.1360 - MAE: 1.6208\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 3.4513 - MAE: 1.5025\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 2.8489 - MAE: 1.3351\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 3.5902 - MAE: 1.4311\n",
      "12/12 [==============================] - 1s 12ms/step - loss: 4.0248 - MAE: 1.5921\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 3.3849 - MAE: 1.4114\n",
      "12/12 [==============================] - 1s 12ms/step - loss: 3.9459 - MAE: 1.5529\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 2.6915 - MAE: 1.2308\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 3.7131 - MAE: 1.4629\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 3.3489 - MAE: 1.4371\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 4.1470 - MAE: 1.6551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BASEL_model': {'loss': 3.130190134048462, 'MAE': 1.412452220916748},\n",
       " 'BUDAPEST_model': {'loss': 3.431553363800049, 'MAE': 1.4174083471298218},\n",
       " 'DE_model': {'loss': 3.04231858253479, 'MAE': 1.3951071500778198},\n",
       " 'DRESDEN_model': {'loss': 4.662763595581055, 'MAE': 1.6595466136932373},\n",
       " 'DUSSELDORF_model': {'loss': 2.7651171684265137, 'MAE': 1.3485355377197266},\n",
       " 'HEATHROW_model': {'loss': 2.336878538131714, 'MAE': 1.2040523290634155},\n",
       " 'KASSEL_model': {'loss': 3.063828468322754, 'MAE': 1.3915371894836426},\n",
       " 'LJUBLJANA_model': {'loss': 4.13596773147583, 'MAE': 1.6207607984542847},\n",
       " 'MAASTRICHT_model': {'loss': 3.4513332843780518, 'MAE': 1.5025049448013306},\n",
       " 'MALMO_model': {'loss': 2.8489317893981934, 'MAE': 1.3350719213485718},\n",
       " 'MONTELIMAR_model': {'loss': 3.59019136428833, 'MAE': 1.4311318397521973},\n",
       " 'MUENCHEN_model': {'loss': 4.0247802734375, 'MAE': 1.5921064615249634},\n",
       " 'OSLO_model': {'loss': 3.3848774433135986, 'MAE': 1.411376953125},\n",
       " 'PERPIGNAN_model': {'loss': 3.945852279663086, 'MAE': 1.5528568029403687},\n",
       " 'ROMA_model': {'loss': 2.691511392593384, 'MAE': 1.2308226823806763},\n",
       " 'SONNBLICK_model': {'loss': 3.7130675315856934, 'MAE': 1.46293306350708},\n",
       " 'STOCKHOLM_model': {'loss': 3.3489131927490234, 'MAE': 1.437125563621521},\n",
       " 'TOURS_model': {'loss': 4.146976470947266, 'MAE': 1.6550631523132324}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_losses = dict()\n",
    "for model, batch_data in zip(models, batch_dataset):\n",
    "    loss, mae = model.evaluate(batch_data[1])\n",
    "    model_losses[model.name] = {\"loss\": loss, \"MAE\": mae}\n",
    "model_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_model</th>\n",
       "      <th>BUDAPEST_model</th>\n",
       "      <th>DE_model</th>\n",
       "      <th>DRESDEN_model</th>\n",
       "      <th>DUSSELDORF_model</th>\n",
       "      <th>HEATHROW_model</th>\n",
       "      <th>KASSEL_model</th>\n",
       "      <th>LJUBLJANA_model</th>\n",
       "      <th>MAASTRICHT_model</th>\n",
       "      <th>MALMO_model</th>\n",
       "      <th>MONTELIMAR_model</th>\n",
       "      <th>MUENCHEN_model</th>\n",
       "      <th>OSLO_model</th>\n",
       "      <th>PERPIGNAN_model</th>\n",
       "      <th>ROMA_model</th>\n",
       "      <th>SONNBLICK_model</th>\n",
       "      <th>STOCKHOLM_model</th>\n",
       "      <th>TOURS_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>3.130190</td>\n",
       "      <td>3.431553</td>\n",
       "      <td>3.042319</td>\n",
       "      <td>4.662764</td>\n",
       "      <td>2.765117</td>\n",
       "      <td>2.336879</td>\n",
       "      <td>3.063828</td>\n",
       "      <td>4.135968</td>\n",
       "      <td>3.451333</td>\n",
       "      <td>2.848932</td>\n",
       "      <td>3.590191</td>\n",
       "      <td>4.024780</td>\n",
       "      <td>3.384877</td>\n",
       "      <td>3.945852</td>\n",
       "      <td>2.691511</td>\n",
       "      <td>3.713068</td>\n",
       "      <td>3.348913</td>\n",
       "      <td>4.146976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.412452</td>\n",
       "      <td>1.417408</td>\n",
       "      <td>1.395107</td>\n",
       "      <td>1.659547</td>\n",
       "      <td>1.348536</td>\n",
       "      <td>1.204052</td>\n",
       "      <td>1.391537</td>\n",
       "      <td>1.620761</td>\n",
       "      <td>1.502505</td>\n",
       "      <td>1.335072</td>\n",
       "      <td>1.431132</td>\n",
       "      <td>1.592106</td>\n",
       "      <td>1.411377</td>\n",
       "      <td>1.552857</td>\n",
       "      <td>1.230823</td>\n",
       "      <td>1.462933</td>\n",
       "      <td>1.437126</td>\n",
       "      <td>1.655063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BASEL_model  BUDAPEST_model  DE_model  DRESDEN_model  DUSSELDORF_model  \\\n",
       "loss     3.130190        3.431553  3.042319       4.662764          2.765117   \n",
       "MAE      1.412452        1.417408  1.395107       1.659547          1.348536   \n",
       "\n",
       "      HEATHROW_model  KASSEL_model  LJUBLJANA_model  MAASTRICHT_model  \\\n",
       "loss        2.336879      3.063828         4.135968          3.451333   \n",
       "MAE         1.204052      1.391537         1.620761          1.502505   \n",
       "\n",
       "      MALMO_model  MONTELIMAR_model  MUENCHEN_model  OSLO_model  \\\n",
       "loss     2.848932          3.590191        4.024780    3.384877   \n",
       "MAE      1.335072          1.431132        1.592106    1.411377   \n",
       "\n",
       "      PERPIGNAN_model  ROMA_model  SONNBLICK_model  STOCKHOLM_model  \\\n",
       "loss         3.945852    2.691511         3.713068         3.348913   \n",
       "MAE          1.552857    1.230823         1.462933         1.437126   \n",
       "\n",
       "      TOURS_model  \n",
       "loss     4.146976  \n",
       "MAE      1.655063  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_df = pd.DataFrame(model_losses)\n",
    "model_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss    3.428614\n",
       "MAE     1.447800\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('keras')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1adc45b2727d29ffe2ebdf1744bac2997f1014da1e47286e1a4198fcda79fd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
