{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:03:46.112024: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 20:03:46.311488: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-17 20:03:47.226495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-17 20:03:47.226593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-17 20:03:47.226603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/BASEL',\n",
       " './model/BUDAPEST',\n",
       " './model/DE',\n",
       " './model/DRESDEN',\n",
       " './model/DUSSELDORF',\n",
       " './model/HEATHROW',\n",
       " './model/KASSEL',\n",
       " './model/LJUBLJANA',\n",
       " './model/MAASTRICHT',\n",
       " './model/MALMO',\n",
       " './model/MONTELIMAR',\n",
       " './model/MUENCHEN',\n",
       " './model/OSLO',\n",
       " './model/PERPIGNAN',\n",
       " './model/ROMA',\n",
       " './model/SONNBLICK',\n",
       " './model/STOCKHOLM',\n",
       " './model/TOURS']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model_dirs = [\n",
    "    os.path.join(os.curdir, \"model\", name)\n",
    "    for name in sorted(os.listdir(os.path.join(os.curdir, \"model\")))\n",
    "]\n",
    "model_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:03:48.221776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:48.240951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:48.241981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:48.242768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 20:03:48.270486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:48.271088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:48.271689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:49.633698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:49.634190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:49.634245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-11-17 20:03:49.634676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 20:03:49.634727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10149 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BUDAPEST_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 6, 8)]            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 6, 16)             1600      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,729\n",
      "Trainable params: 3,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = [tf.keras.models.load_model(model_dir) for model_dir in model_dirs]\n",
    "models[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_DIR = os.path.join(os.curdir, \"dataset\", \"sorted\")\n",
    "csv_filenames = sorted(os.listdir(CSV_DIR))\n",
    "csv_dataset = [\n",
    "    pd.read_csv(os.path.join(CSV_DIR, filename)) for filename in csv_filenames\n",
    "]\n",
    "print(len(csv_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(<BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>, <BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>, <BatchDataset element_spec=(TensorSpec(shape=(None, None, 8), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>)\n",
      "tf.Tensor(\n",
      "[[ 1.11010855  1.34424888  1.34682202 -1.20851298 -0.38199123 -1.07646018\n",
      "  -1.09549112 -0.80998751 -1.33429094]\n",
      " [ 1.11010855  1.15869866  1.7487146  -1.15505695 -0.43793346 -1.07646018\n",
      "  -1.00108475 -0.64465741 -1.23109558]\n",
      " [-0.17993809  0.602048    1.69847803 -0.8877768  -0.43793346 -0.22197883\n",
      "  -1.18989749 -1.03543765 -1.23109558]\n",
      " [ 0.680093    0.41649778  1.04540259 -0.74879112  0.2147259   0.51703206\n",
      "  -0.96062487 -0.97531762 -0.92150951]\n",
      " [-0.17993809  1.43702399  0.8444563  -0.87708559 -0.30740159 -0.22197883\n",
      "  -0.67740576 -0.47932731 -0.79538185]\n",
      " [-1.03996918  0.97314844  0.81933801 -0.82362956 -0.43793346  0.23990298\n",
      "  -0.920165   -0.76489749 -0.99030641]], shape=(6, 9), dtype=float64)\n",
      "tf.Tensor([4.7], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_END_INDEX = 2922\n",
    "VALIDATION_END_INDEX = 3288\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    dataset: pd.DataFrame,\n",
    "    sequence_length,\n",
    "    batch_size,\n",
    "    train_end_index,\n",
    "    validation_end_index,\n",
    "):\n",
    "    data = dataset\n",
    "    for col in dataset.columns:\n",
    "        if \"temp_mean\" in col:\n",
    "            target = pd.DataFrame(dataset[col])\n",
    "            data = data.drop(columns=[\"DATE\"])\n",
    "            break\n",
    "    scaled_data = (data - data.mean(axis=0)) / data.std(axis=0)\n",
    "    train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=0,\n",
    "        end_index=train_end_index,\n",
    "    )\n",
    "    validation_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=train_end_index,\n",
    "        end_index=validation_end_index,\n",
    "    )\n",
    "    test_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=validation_end_index,\n",
    "    )\n",
    "    return (train_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "\n",
    "sequence_length = 6\n",
    "\n",
    "batch_dataset = [\n",
    "    get_dataset(csv_data, sequence_length, 32, TRAIN_END_INDEX, VALIDATION_END_INDEX)\n",
    "    for csv_data in csv_dataset\n",
    "]\n",
    "\n",
    "print(len(batch_dataset))\n",
    "print(batch_dataset[1])\n",
    "for data, label in batch_dataset[0][0]:\n",
    "    print(data[0])\n",
    "    print(label[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 20:05:36.345274: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 17ms/step - loss: 3.9856 - MAE: 1.5323\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 3.8023 - MAE: 1.4962\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 3.1464 - MAE: 1.4127\n",
      "12/12 [==============================] - 1s 16ms/step - loss: 4.3178 - MAE: 1.6210\n",
      "12/12 [==============================] - 1s 17ms/step - loss: 3.8852 - MAE: 1.5584\n",
      "12/12 [==============================] - 1s 12ms/step - loss: 1.5892 - MAE: 0.9812\n",
      "12/12 [==============================] - 1s 17ms/step - loss: 3.9405 - MAE: 1.5300\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 4.6420 - MAE: 1.6384\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 4.3637 - MAE: 1.6282\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 3.0828 - MAE: 1.3481\n",
      "12/12 [==============================] - 1s 20ms/step - loss: 3.4046 - MAE: 1.4873\n",
      "12/12 [==============================] - 1s 25ms/step - loss: 4.7022 - MAE: 1.6909\n",
      "12/12 [==============================] - 1s 17ms/step - loss: 3.2047 - MAE: 1.3808\n",
      "12/12 [==============================] - 1s 13ms/step - loss: 4.2670 - MAE: 1.6168\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 2.8988 - MAE: 1.2684\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 4.2548 - MAE: 1.5946\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 3.0758 - MAE: 1.3531\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 4.0815 - MAE: 1.6223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BASEL_model': {'loss': 3.9856207370758057, 'MAE': 1.5322635173797607},\n",
       " 'BUDAPEST_model': {'loss': 3.8022818565368652, 'MAE': 1.49616539478302},\n",
       " 'DE_model': {'loss': 3.146448850631714, 'MAE': 1.412664532661438},\n",
       " 'DRESDEN_model': {'loss': 4.31781005859375, 'MAE': 1.6209954023361206},\n",
       " 'DUSSELDORF_model': {'loss': 3.885239839553833, 'MAE': 1.5584055185317993},\n",
       " 'HEATHROW_model': {'loss': 1.5891635417938232, 'MAE': 0.9812320470809937},\n",
       " 'KASSEL_model': {'loss': 3.940459966659546, 'MAE': 1.5299921035766602},\n",
       " 'LJUBLJANA_model': {'loss': 4.642023086547852, 'MAE': 1.638442039489746},\n",
       " 'MAASTRICHT_model': {'loss': 4.363713264465332, 'MAE': 1.6281614303588867},\n",
       " 'MALMO_model': {'loss': 3.0827739238739014, 'MAE': 1.348146915435791},\n",
       " 'MONTELIMAR_model': {'loss': 3.4046170711517334, 'MAE': 1.4872580766677856},\n",
       " 'MUENCHEN_model': {'loss': 4.702232837677002, 'MAE': 1.6908601522445679},\n",
       " 'OSLO_model': {'loss': 3.2046892642974854, 'MAE': 1.3807661533355713},\n",
       " 'PERPIGNAN_model': {'loss': 4.267011642456055, 'MAE': 1.6168211698532104},\n",
       " 'ROMA_model': {'loss': 2.898796796798706, 'MAE': 1.2683950662612915},\n",
       " 'SONNBLICK_model': {'loss': 4.254802227020264, 'MAE': 1.594639778137207},\n",
       " 'STOCKHOLM_model': {'loss': 3.0757830142974854, 'MAE': 1.3530980348587036},\n",
       " 'TOURS_model': {'loss': 4.081547260284424, 'MAE': 1.6222620010375977}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_losses = dict()\n",
    "for model, batch_data in zip(models, batch_dataset):\n",
    "    loss, mae = model.evaluate(batch_data[2])\n",
    "    model_losses[model.name] = {\"loss\": loss, \"MAE\": mae}\n",
    "model_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_model</th>\n",
       "      <th>BUDAPEST_model</th>\n",
       "      <th>DE_model</th>\n",
       "      <th>DRESDEN_model</th>\n",
       "      <th>DUSSELDORF_model</th>\n",
       "      <th>HEATHROW_model</th>\n",
       "      <th>KASSEL_model</th>\n",
       "      <th>LJUBLJANA_model</th>\n",
       "      <th>MAASTRICHT_model</th>\n",
       "      <th>MALMO_model</th>\n",
       "      <th>MONTELIMAR_model</th>\n",
       "      <th>MUENCHEN_model</th>\n",
       "      <th>OSLO_model</th>\n",
       "      <th>PERPIGNAN_model</th>\n",
       "      <th>ROMA_model</th>\n",
       "      <th>SONNBLICK_model</th>\n",
       "      <th>STOCKHOLM_model</th>\n",
       "      <th>TOURS_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>3.985621</td>\n",
       "      <td>3.802282</td>\n",
       "      <td>3.146449</td>\n",
       "      <td>4.317810</td>\n",
       "      <td>3.885240</td>\n",
       "      <td>1.589164</td>\n",
       "      <td>3.940460</td>\n",
       "      <td>4.642023</td>\n",
       "      <td>4.363713</td>\n",
       "      <td>3.082774</td>\n",
       "      <td>3.404617</td>\n",
       "      <td>4.702233</td>\n",
       "      <td>3.204689</td>\n",
       "      <td>4.267012</td>\n",
       "      <td>2.898797</td>\n",
       "      <td>4.254802</td>\n",
       "      <td>3.075783</td>\n",
       "      <td>4.081547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.532264</td>\n",
       "      <td>1.496165</td>\n",
       "      <td>1.412665</td>\n",
       "      <td>1.620995</td>\n",
       "      <td>1.558406</td>\n",
       "      <td>0.981232</td>\n",
       "      <td>1.529992</td>\n",
       "      <td>1.638442</td>\n",
       "      <td>1.628161</td>\n",
       "      <td>1.348147</td>\n",
       "      <td>1.487258</td>\n",
       "      <td>1.690860</td>\n",
       "      <td>1.380766</td>\n",
       "      <td>1.616821</td>\n",
       "      <td>1.268395</td>\n",
       "      <td>1.594640</td>\n",
       "      <td>1.353098</td>\n",
       "      <td>1.622262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BASEL_model  BUDAPEST_model  DE_model  DRESDEN_model  DUSSELDORF_model  \\\n",
       "loss     3.985621        3.802282  3.146449       4.317810          3.885240   \n",
       "MAE      1.532264        1.496165  1.412665       1.620995          1.558406   \n",
       "\n",
       "      HEATHROW_model  KASSEL_model  LJUBLJANA_model  MAASTRICHT_model  \\\n",
       "loss        1.589164      3.940460         4.642023          4.363713   \n",
       "MAE         0.981232      1.529992         1.638442          1.628161   \n",
       "\n",
       "      MALMO_model  MONTELIMAR_model  MUENCHEN_model  OSLO_model  \\\n",
       "loss     3.082774          3.404617        4.702233    3.204689   \n",
       "MAE      1.348147          1.487258        1.690860    1.380766   \n",
       "\n",
       "      PERPIGNAN_model  ROMA_model  SONNBLICK_model  STOCKHOLM_model  \\\n",
       "loss         4.267012    2.898797         4.254802         3.075783   \n",
       "MAE          1.616821    1.268395         1.594640         1.353098   \n",
       "\n",
       "      TOURS_model  \n",
       "loss     4.081547  \n",
       "MAE      1.622262  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_df = pd.DataFrame(model_losses)\n",
    "model_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss    3.702501\n",
       "MAE     1.486698\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_df.mean(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('keras')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1adc45b2727d29ffe2ebdf1744bac2997f1014da1e47286e1a4198fcda79fd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
