{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 15:10:47.151244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 15:10:47.558078: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-17 15:10:48.608640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-17 15:10:48.608735: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-17 15:10:48.608744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/BASEL',\n",
       " './model/BUDAPEST',\n",
       " './model/DE',\n",
       " './model/DRESDEN',\n",
       " './model/DUSSELDORF',\n",
       " './model/HEATHROW',\n",
       " './model/KASSEL',\n",
       " './model/LJUBLJANA',\n",
       " './model/MAASTRICHT',\n",
       " './model/MALMO',\n",
       " './model/MONTELIMAR',\n",
       " './model/MUENCHEN',\n",
       " './model/OSLO',\n",
       " './model/PERPIGNAN',\n",
       " './model/ROMA',\n",
       " './model/SONNBLICK',\n",
       " './model/STOCKHOLM',\n",
       " './model/TOURS']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model_dirs = [\n",
    "    os.path.join(os.curdir, \"model\", name)\n",
    "    for name in sorted(os.listdir(os.path.join(os.curdir, \"model\")))\n",
    "]\n",
    "model_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 15:10:50.144791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:50.185000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:50.185583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:50.186964: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 15:10:50.195953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:50.196376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:50.196785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:51.338798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:51.340283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:51.340297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-11-17 15:10:51.340811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:42:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-11-17 15:10:51.340854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22124 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:42:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BUDAPEST_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 6, 7)]            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 6, 16)             1536      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 16)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,665\n",
      "Trainable params: 3,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = [tf.keras.models.load_model(model_dir) for model_dir in model_dirs]\n",
    "models[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_DIR = os.path.join(os.curdir, \"dataset\", \"sorted\")\n",
    "csv_filenames = sorted(os.listdir(CSV_DIR))\n",
    "csv_dataset = [\n",
    "    pd.read_csv(os.path.join(CSV_DIR, filename)) for filename in csv_filenames\n",
    "]\n",
    "print(len(csv_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(<BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>, <BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>, <BatchDataset element_spec=(TensorSpec(shape=(None, None, 7), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>)\n",
      "tf.Tensor(\n",
      "[[ 1.34424888  1.34682202 -1.20851298 -0.38199123 -1.07646018 -1.09549112\n",
      "  -0.80998751 -1.33429094]\n",
      " [ 1.15869866  1.7487146  -1.15505695 -0.43793346 -1.07646018 -1.00108475\n",
      "  -0.64465741 -1.23109558]\n",
      " [ 0.602048    1.69847803 -0.8877768  -0.43793346 -0.22197883 -1.18989749\n",
      "  -1.03543765 -1.23109558]\n",
      " [ 0.41649778  1.04540259 -0.74879112  0.2147259   0.51703206 -0.96062487\n",
      "  -0.97531762 -0.92150951]\n",
      " [ 1.43702399  0.8444563  -0.87708559 -0.30740159 -0.22197883 -0.67740576\n",
      "  -0.47932731 -0.79538185]\n",
      " [ 0.97314844  0.81933801 -0.82362956 -0.43793346  0.23990298 -0.920165\n",
      "  -0.76489749 -0.99030641]], shape=(6, 8), dtype=float64)\n",
      "tf.Tensor([4.7], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TRAIN_END_INDEX = 2922\n",
    "VALIDATION_END_INDEX = 3288\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    dataset: pd.DataFrame,\n",
    "    sequence_length,\n",
    "    batch_size,\n",
    "    train_end_index,\n",
    "    validation_end_index,\n",
    "):\n",
    "    data = dataset\n",
    "    for col in dataset.columns:\n",
    "        if \"temp_mean\" in col:\n",
    "            target = pd.DataFrame(dataset[col])\n",
    "            data = data.drop(columns=[\"DATE\"])\n",
    "            break\n",
    "    scaled_data = (data - data.mean(axis=0)) / data.std(axis=0)\n",
    "    train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=0,\n",
    "        end_index=train_end_index,\n",
    "    )\n",
    "    validation_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=train_end_index,\n",
    "        end_index=validation_end_index,\n",
    "    )\n",
    "    test_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "        scaled_data[:-sequence_length],\n",
    "        targets=target[sequence_length:],\n",
    "        sequence_length=sequence_length,\n",
    "        batch_size=batch_size,\n",
    "        start_index=validation_end_index,\n",
    "    )\n",
    "    return (train_dataset, validation_dataset, test_dataset)\n",
    "\n",
    "\n",
    "sequence_length = 6\n",
    "\n",
    "batch_dataset = [\n",
    "    get_dataset(csv_data, sequence_length, 32, TRAIN_END_INDEX, VALIDATION_END_INDEX)\n",
    "    for csv_data in csv_dataset\n",
    "]\n",
    "\n",
    "print(len(batch_dataset))\n",
    "print(batch_dataset[1])\n",
    "for data, label in batch_dataset[0][0]:\n",
    "    print(data[0])\n",
    "    print(label[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 15:11:49.009854: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 10ms/step - loss: 3.9772 - MAE: 1.5624\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 3.9238 - MAE: 1.5208\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 3.1649 - MAE: 1.4026\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 4.3643 - MAE: 1.6324\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 3.7655 - MAE: 1.5310\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 1.6749 - MAE: 1.0142\n",
      "12/12 [==============================] - 1s 11ms/step - loss: 3.7375 - MAE: 1.4786\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 4.8968 - MAE: 1.6802\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 4.1795 - MAE: 1.5893\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 2.7624 - MAE: 1.2744\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 3.6955 - MAE: 1.5372\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 4.7818 - MAE: 1.7043\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 3.1109 - MAE: 1.3379\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 4.4349 - MAE: 1.6456\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 2.4800 - MAE: 1.1424\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 4.1445 - MAE: 1.5810\n",
      "12/12 [==============================] - 1s 9ms/step - loss: 3.0392 - MAE: 1.3536\n",
      "12/12 [==============================] - 1s 10ms/step - loss: 4.4037 - MAE: 1.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BASEL_model': {'loss': 3.9772305488586426, 'MAE': 1.562368631362915},\n",
       " 'BUDAPEST_model': {'loss': 3.9238288402557373, 'MAE': 1.5208358764648438},\n",
       " 'DE_model': {'loss': 3.1648616790771484, 'MAE': 1.4026259183883667},\n",
       " 'DRESDEN_model': {'loss': 4.364295959472656, 'MAE': 1.6324210166931152},\n",
       " 'DUSSELDORF_model': {'loss': 3.765521764755249, 'MAE': 1.53096342086792},\n",
       " 'HEATHROW_model': {'loss': 1.6749207973480225, 'MAE': 1.0141819715499878},\n",
       " 'KASSEL_model': {'loss': 3.737462282180786, 'MAE': 1.4786101579666138},\n",
       " 'LJUBLJANA_model': {'loss': 4.896814346313477, 'MAE': 1.6801944971084595},\n",
       " 'MAASTRICHT_model': {'loss': 4.179484844207764, 'MAE': 1.5893174409866333},\n",
       " 'MALMO_model': {'loss': 2.7623682022094727, 'MAE': 1.274404525756836},\n",
       " 'MONTELIMAR_model': {'loss': 3.695478916168213, 'MAE': 1.5372430086135864},\n",
       " 'MUENCHEN_model': {'loss': 4.781796455383301, 'MAE': 1.7042547464370728},\n",
       " 'OSLO_model': {'loss': 3.1108672618865967, 'MAE': 1.337936282157898},\n",
       " 'PERPIGNAN_model': {'loss': 4.434859275817871, 'MAE': 1.6455614566802979},\n",
       " 'ROMA_model': {'loss': 2.480038642883301, 'MAE': 1.1423591375350952},\n",
       " 'SONNBLICK_model': {'loss': 4.144466876983643, 'MAE': 1.5810056924819946},\n",
       " 'STOCKHOLM_model': {'loss': 3.0392298698425293, 'MAE': 1.3536009788513184},\n",
       " 'TOURS_model': {'loss': 4.403682231903076, 'MAE': 1.6622910499572754}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_losses = dict()\n",
    "for model, batch_data in zip(models, batch_dataset):\n",
    "    loss, mae = model.evaluate(batch_data[2])\n",
    "    model_losses[model.name] = {\"loss\": loss, \"MAE\": mae}\n",
    "model_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BASEL_model</th>\n",
       "      <th>BUDAPEST_model</th>\n",
       "      <th>DE_model</th>\n",
       "      <th>DRESDEN_model</th>\n",
       "      <th>DUSSELDORF_model</th>\n",
       "      <th>HEATHROW_model</th>\n",
       "      <th>KASSEL_model</th>\n",
       "      <th>LJUBLJANA_model</th>\n",
       "      <th>MAASTRICHT_model</th>\n",
       "      <th>MALMO_model</th>\n",
       "      <th>MONTELIMAR_model</th>\n",
       "      <th>MUENCHEN_model</th>\n",
       "      <th>OSLO_model</th>\n",
       "      <th>PERPIGNAN_model</th>\n",
       "      <th>ROMA_model</th>\n",
       "      <th>SONNBLICK_model</th>\n",
       "      <th>STOCKHOLM_model</th>\n",
       "      <th>TOURS_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>3.977231</td>\n",
       "      <td>3.923829</td>\n",
       "      <td>3.164862</td>\n",
       "      <td>4.364296</td>\n",
       "      <td>3.765522</td>\n",
       "      <td>1.674921</td>\n",
       "      <td>3.737462</td>\n",
       "      <td>4.896814</td>\n",
       "      <td>4.179485</td>\n",
       "      <td>2.762368</td>\n",
       "      <td>3.695479</td>\n",
       "      <td>4.781796</td>\n",
       "      <td>3.110867</td>\n",
       "      <td>4.434859</td>\n",
       "      <td>2.480039</td>\n",
       "      <td>4.144467</td>\n",
       "      <td>3.039230</td>\n",
       "      <td>4.403682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.562369</td>\n",
       "      <td>1.520836</td>\n",
       "      <td>1.402626</td>\n",
       "      <td>1.632421</td>\n",
       "      <td>1.530963</td>\n",
       "      <td>1.014182</td>\n",
       "      <td>1.478610</td>\n",
       "      <td>1.680194</td>\n",
       "      <td>1.589317</td>\n",
       "      <td>1.274405</td>\n",
       "      <td>1.537243</td>\n",
       "      <td>1.704255</td>\n",
       "      <td>1.337936</td>\n",
       "      <td>1.645561</td>\n",
       "      <td>1.142359</td>\n",
       "      <td>1.581006</td>\n",
       "      <td>1.353601</td>\n",
       "      <td>1.662291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BASEL_model  BUDAPEST_model  DE_model  DRESDEN_model  DUSSELDORF_model  \\\n",
       "loss     3.977231        3.923829  3.164862       4.364296          3.765522   \n",
       "MAE      1.562369        1.520836  1.402626       1.632421          1.530963   \n",
       "\n",
       "      HEATHROW_model  KASSEL_model  LJUBLJANA_model  MAASTRICHT_model  \\\n",
       "loss        1.674921      3.737462         4.896814          4.179485   \n",
       "MAE         1.014182      1.478610         1.680194          1.589317   \n",
       "\n",
       "      MALMO_model  MONTELIMAR_model  MUENCHEN_model  OSLO_model  \\\n",
       "loss     2.762368          3.695479        4.781796    3.110867   \n",
       "MAE      1.274405          1.537243        1.704255    1.337936   \n",
       "\n",
       "      PERPIGNAN_model  ROMA_model  SONNBLICK_model  STOCKHOLM_model  \\\n",
       "loss         4.434859    2.480039         4.144467         3.039230   \n",
       "MAE          1.645561    1.142359         1.581006         1.353601   \n",
       "\n",
       "      TOURS_model  \n",
       "loss     4.403682  \n",
       "MAE      1.662291  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_df = pd.DataFrame(model_losses)\n",
    "model_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss    3.696512\n",
       "MAE     1.480565\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss_df.mean(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('keras')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1adc45b2727d29ffe2ebdf1744bac2997f1014da1e47286e1a4198fcda79fd8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
